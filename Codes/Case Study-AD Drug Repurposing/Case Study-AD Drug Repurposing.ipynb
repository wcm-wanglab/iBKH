{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e79254d8",
   "metadata": {},
   "source": [
    "# Alzheimer's Disease Drugs Repurposing via pre-trained embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46eec09f",
   "metadata": {},
   "source": [
    "This is an example showing that conduct AD drug repurposing by using iBKH with pre-trained embedding information. We used pre-trained iBKH embedding information from different models as input, then predicted the most likely associated entity with Alzheimer's Disease (AD)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f67c283",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch as th\n",
    "import torch.nn.functional as fn\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c37530",
   "metadata": {},
   "source": [
    "### Predict Score Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83aa52e1",
   "metadata": {},
   "source": [
    "We used the following algorithms to calculate the edge scores. And the edge scores indicate the strength of association between candidate entities and AD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd69f021",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transE_l2(head, rel, tail, gamma=12.0):\n",
    "    score = head + rel - tail\n",
    "    return gamma - th.norm(score, p=2, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5800845b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transR(head, rel, tail, proj, rel_idx, gamma=12.0):\n",
    "    proj = proj.reshape(-1, head.shape[1], rel.shape[0])[rel_idx]\n",
    "    head_r = th.einsum('ab,bc->ac', head, proj)\n",
    "    tail_r = th.einsum('b,bc->c', th.tensor(tail), proj)\n",
    "    score = head_r + rel - tail_r\n",
    "    return gamma - th.norm(score, p=1, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69db0f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DistMult(head, rel, tail):\n",
    "    score = head * rel * tail\n",
    "    return th.sum(score, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af97a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complEx(head, rel, tail, gamma=12.0):\n",
    "    real_head, img_head = th.chunk(head, 2, dim=-1)\n",
    "    real_tail, img_tail = th.chunk(th.tensor(tail), 2, dim=-1)\n",
    "    real_rel, img_rel = th.chunk(rel, 2, dim=-1)\n",
    "\n",
    "    score = real_head * real_tail * real_rel \\\n",
    "            + img_head * img_tail * real_rel \\\n",
    "            + real_head * img_tail * img_rel \\\n",
    "            - img_head * real_tail * img_rel\n",
    "    # TODO: check if there exists minus sign and if gamma should be used here(jin)\n",
    "    return th.sum(score, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8faa2811",
   "metadata": {},
   "source": [
    "### XModel Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ac073b",
   "metadata": {},
   "source": [
    "We used pre-trained embedding information from the different models to predict the association between the candidate drugs and AD. All the candidate drugs are FDA-approved. We rank the results based on the predict score functions. The larger the score is, the stronger association between candidate drugs and AD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5454abaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'Data/'\n",
    "candidate_D_folder = 'Data/candidate_drugs/'\n",
    "kg_folder = '../iBKH/iBKH_May_3/'\n",
    "result_folder = 'predict_result/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1001911",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xModel_prediction(model_name, trail_status):\n",
    "    entity_df = pd.read_table(folder + model_name + '/entities.tsv', header=None)\n",
    "    entity_df = entity_df.dropna().reset_index(drop=True)\n",
    "    approved_drug_df = pd.read_csv(candidate_D_folder + 'candidate_drugs_' + trail_status + '.csv')\n",
    "    approved_drug_list = list(approved_drug_df['Drug'])\n",
    "\n",
    "    entity_map = {}\n",
    "    entity_id_map = {}\n",
    "    relation_map = {}\n",
    "    drug_ids = []\n",
    "    drug_names = []\n",
    "    disease_ids = []\n",
    "\n",
    "    for i in range(len(entity_df)):\n",
    "        entity_id = entity_df.loc[i, 0]\n",
    "        entity_name = entity_df.loc[i, 1]\n",
    "        entity_map[entity_name] = int(entity_id)\n",
    "        entity_id_map[int(entity_id)] = entity_name\n",
    "        if entity_name.replace('DrugBank:', '') in approved_drug_list:\n",
    "            drug_ids.append(entity_id)\n",
    "            drug_names.append(entity_name.replace('DrugBank:', ''))\n",
    "\n",
    "    disease_vocab = pd.read_csv(kg_folder + 'Entity/disease_vocab.csv')\n",
    "    AD_related_list = []\n",
    "    for i in range(len(disease_vocab)):\n",
    "        primary_id = disease_vocab.loc[i, 'primary']\n",
    "        disease_name = disease_vocab.loc[i, 'name']\n",
    "        disease_name = disease_name if not pd.isnull(disease_name) else ''\n",
    "        if 'alzheimer' in disease_name:\n",
    "            if primary_id not in AD_related_list:\n",
    "                AD_related_list.append(primary_id)\n",
    "\n",
    "    relation_df = pd.read_table(folder + model_name + '/relations.tsv', header=None)\n",
    "    for i in range(len(relation_df)):\n",
    "        relation_id = relation_df.loc[i, 0]\n",
    "        relation_name = relation_df.loc[i, 1]\n",
    "        relation_map[relation_name] = int(relation_id)\n",
    "\n",
    "    for disease in AD_related_list:\n",
    "        if disease in entity_map:\n",
    "            disease_ids.append(entity_map[disease])\n",
    "\n",
    "    entity_emb = np.load(folder + model_name + '/iBKH_' + model_name + '_entity.npy')\n",
    "    rel_emb = np.load(folder + model_name + '/iBKH_' + model_name + '_relation.npy')\n",
    "    if model_name == 'TransR':\n",
    "        proj_np = np.load(folder + 'TransR/iBKH_TransRprojection.npy')\n",
    "        proj_emb = th.tensor(proj_np)\n",
    "\n",
    "    treatment = ['Treats_DDi', 'Palliates_DDi', 'Effect_DDi', 'Associate_DDi', 'Inferred_Relation_DDi',\n",
    "                 'Semantic_Relation_DDi']\n",
    "    treatment_rid = [relation_map[treat] for treat in treatment]\n",
    "\n",
    "    drug_ids = th.tensor(drug_ids).long()\n",
    "    disease_ids = th.tensor(disease_ids).long()\n",
    "    treatment_rid = th.tensor(treatment_rid)\n",
    "\n",
    "    drug_emb = th.tensor(entity_emb[drug_ids])\n",
    "    treatment_embs = [th.tensor(rel_emb[rid]) for rid in treatment_rid]\n",
    "\n",
    "    scores_per_disease = []\n",
    "    dids = []\n",
    "    for rid in range(len(treatment_embs)):\n",
    "        treatment_emb = treatment_embs[rid]\n",
    "        for disease_id in disease_ids:\n",
    "            disease_emb = th.tensor(entity_emb[disease_id])\n",
    "            if model_name == 'RotatE':\n",
    "                score = fn.logsigmoid(rotatE(drug_emb, treatment_emb, disease_emb))\n",
    "            elif model_name == 'ComplEx':\n",
    "                score = fn.logsigmoid(complEx(drug_emb, treatment_emb, disease_emb))\n",
    "            elif model_name == 'TransR':\n",
    "                score = fn.logsigmoid(transR(drug_emb, treatment_emb, disease_emb, proj_emb, treatment_rid[rid]))\n",
    "            elif model_name == 'TransE_l2':\n",
    "                score = fn.logsigmoid(transE_l2(drug_emb, treatment_emb, disease_emb))\n",
    "            elif model_name == 'DistMult':\n",
    "                score = fn.logsigmoid(DistMult(drug_emb, treatment_emb, disease_emb))\n",
    "            scores_per_disease.append(score)\n",
    "            dids.append(drug_ids)\n",
    "    scores = th.cat(scores_per_disease)\n",
    "    dids = th.cat(dids)\n",
    "\n",
    "    idx = th.flip(th.argsort(scores), dims=[0])\n",
    "    scores = scores[idx].numpy()\n",
    "    dids = dids[idx].numpy()\n",
    "\n",
    "    _, unique_indices = np.unique(dids, return_index=True)\n",
    "    topk_indices = np.sort(unique_indices)\n",
    "    proposed_dids = dids[topk_indices]\n",
    "    proposed_scores = scores[topk_indices]\n",
    "\n",
    "    candidate_drug_rank = []\n",
    "    candidate_drug_score = {}\n",
    "    for i, idx in enumerate(proposed_dids):\n",
    "        candidate_drug_rank.append(entity_id_map[int(idx)].replace('DrugBank:', ''))\n",
    "        candidate_drug_score[entity_id_map[int(idx)].replace('DrugBank:', '')] = proposed_scores[i]\n",
    "\n",
    "    df = pd.DataFrame(columns=['Drug', 'Score'])\n",
    "    idx = 0\n",
    "    for drug in candidate_drug_score:\n",
    "        df.loc[idx] = [drug, candidate_drug_score[drug]]\n",
    "        idx += 1\n",
    "\n",
    "    x = np.asarray(df['Score']).reshape(-1, 1)  # returns a numpy array\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    x_scaled = min_max_scaler.fit_transform(x)\n",
    "    df['Score_scaled'] = pd.DataFrame(x_scaled)\n",
    "    print(df)\n",
    "    df.to_csv(result_folder + \"predict_result_scaled_\" + model_name + \"_\" + trail_status + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42887935",
   "metadata": {},
   "source": [
    "### ROC Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1f4c8b",
   "metadata": {},
   "source": [
    "We have identified different sets of ground truths based on the clinical trails status of candidate drugs. We used the ranked lists (predict results) obtained from the embedding information to calculate ROC and AUC scores to analyze the performance. The ROC was plotted based on the different thresholds of the false positive and true positive rates. The AUC scores range from 0 to 1, where 1 corresponds to perfect performance and 0.5 indicates random classical performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22055971",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_AUC(model_name):\n",
    "    figures_folder = result_folder + 'auc_figures/'\n",
    "    drug_trail_list = ['approve_phase1234', 'approve_phase234', 'approve_phase34', 'approve_phase4', 'approve']\n",
    "    trail_info = {'approve_phase1234': {'label': 'FDA approved+Phase I~IV', 'color': '#6a4c93'},\n",
    "                  'approve_phase234': {'label': 'FDA approved+Phase II~IV', 'color': '#1982c4'},\n",
    "                  'approve_phase34': {'label': 'FDA approved+Phase III,IV', 'color': '#8ac926'},\n",
    "                  'approve_phase4': {'label': 'FDA approved+Phase IV', 'color': '#ffca3a'},\n",
    "                  'approve': {'label': 'FDA approved', 'color': '#ff595e'}}\n",
    "    plt.figure(figsize=(7, 7))\n",
    "\n",
    "    for trail_status in drug_trail_list:\n",
    "        predict_res = pd.read_csv(result_folder + \"predict_result_scaled_\" + model_name + \"_\" + trail_status + \".csv\")\n",
    "        candidate_df = pd.read_csv(candidate_D_folder + 'candidate_drugs_' + trail_status + '.csv')\n",
    "\n",
    "        df = pd.merge(predict_res, candidate_df, on='Drug')\n",
    "\n",
    "        label = np.array(list(df['label']))\n",
    "        score = np.array(list(df['Score_scaled']))\n",
    "        # score = np.array(list(df['Score']))\n",
    "\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(label, score)\n",
    "        youden = tpr - fpr\n",
    "        youden_J = np.max(youden)\n",
    "        inds_youden_J = np.where(youden == youden_J)\n",
    "        tpr_max = tpr[inds_youden_J]\n",
    "        fpr_max = fpr[inds_youden_J]\n",
    "        cut_off = thresholds[inds_youden_J][0]\n",
    "        sensitivity = tpr_max[0]\n",
    "        specificity = 1 - fpr_max[0]\n",
    "        prevalence = np.where(label == 1)[0].shape[0] / label.shape[0]\n",
    "        acc = (sensitivity * prevalence) + (specificity * (1 - prevalence))\n",
    "        print(cut_off, sensitivity, specificity, acc)\n",
    "        auc = metrics.auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, label=trail_info[trail_status]['label'] + ', AUC=' + str(round(auc, 2)),\n",
    "                 color=trail_info[trail_status]['color'])\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='gray', alpha=.8)\n",
    "    plt.tick_params(labelsize=16, bottom=True, left=True)\n",
    "    plt.xlabel(\"1 - Specificity\", fontsize=12, fontweight='bold')\n",
    "    plt.ylabel(\"Sensitivity\", fontsize=12, fontweight='bold')\n",
    "    plt.grid(alpha=.3)\n",
    "    plt.legend(prop={'size': 12}, loc=4)\n",
    "    plt.title(model_name, fontweight='bold', fontsize=18)\n",
    "    # plt.show()\n",
    "    plt.savefig(figures_folder + model_name + '.pdf', dpi=300)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f712c53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_trail_list = ['approve_phase1234', 'approve_phase234', 'approve_phase34', 'approve_phase4', 'approve']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35fc797",
   "metadata": {},
   "source": [
    "### Prediction & ROC curve (TransE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98d80c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'TransE_l2'\n",
    "for trail_status in drug_trail_list:\n",
    "    xModel_prediction(model_name, trail_status)\n",
    "\n",
    "generate_AUC(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174a5f49",
   "metadata": {},
   "source": [
    "### Prediction & ROC curve (TransR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153a9095",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'TransR'\n",
    "for trail_status in drug_trail_list:\n",
    "    xModel_prediction(model_name, trail_status)\n",
    "\n",
    "generate_AUC(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff19b67",
   "metadata": {},
   "source": [
    "### Prediction & ROC curve (DistMult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42a3fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'DistMult'\n",
    "for trail_status in drug_trail_list:\n",
    "    xModel_prediction(model_name, trail_status)\n",
    "\n",
    "generate_AUC(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a0587f",
   "metadata": {},
   "source": [
    "### Prediction & ROC curve (ComplEx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489b1679",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'ComplEx'\n",
    "for trail_status in drug_trail_list:\n",
    "    xModel_prediction(model_name, trail_status)\n",
    "\n",
    "generate_AUC(model_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
